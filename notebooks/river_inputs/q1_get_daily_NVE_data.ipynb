{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b99eff1a-6f5e-4359-aa63-60b4ca83c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nivapy3 as nivapy\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4823b4-0241-4414-b311-db7496bd8f21",
   "metadata": {},
   "source": [
    "# Download daily river discharge data from NVE\n",
    "\n",
    "Stations of interest for AquaInfra use case:\n",
    "\n",
    "* **Numedalslågen**: Holmfoss i Numedalslågen, 15.61.0, from 1970. About 15 km upstream of land-sea outflow.\n",
    "* **Drammenselva**\n",
    "    - Mjøndalen bru, 12.534.0, from 2004. Most D/S station\n",
    "    - Døvikfoss, 12.285.0, from 1912. About 25 km U/S of Mjøndalen bru, no huge tribs between the two. Just downstream of Tyrifjorden and Gravfoss Kraftverk\n",
    "* **Glomma**\n",
    "    - Solbergfoss, 2.605.0, from 1964. Just downstream of Øyeren. Was the most downstream station for a long time. Estimated rather than measured? «Data ved Solbergfoss beregnes ut fra kraftverksproduksjon og tapping i luker»\n",
    "    - Sarpsborg, 2.489.0, from 2009, Most D/S station. Not in Sildre though, only in NVE Atlas. Lets see if we can get it. Otherwise go for Solbergfoss. **Update: Not available in HydAPI, so drop for now.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d73041-531d-4016-9641-ed9915138038",
   "metadata": {},
   "source": [
    "## 0. User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9f8ad9e-7c62-4f98-8ab7-95bba2d82714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of stations we want per river of interest\n",
    "stn_id_name_dict = {\n",
    "    \"Numedalslågen\": {\"15.61.0\": \"Holmfoss\"},\n",
    "\n",
    "    \"Drammenselva\": {\"12.534.0\": \"Mjøndalen bru\",\n",
    "                     \"12.285.0\": \"Døvikfoss\"},\n",
    "\n",
    "    \"Glomma\": {\"2.605.0\": \"Solbergfoss\",\n",
    "               \"2.489.0\": \"Sarpsborg\"}\n",
    "}\n",
    "\n",
    "# Parameters to download\n",
    "par_ids = [1001]  # Daily mean discharge\n",
    "\n",
    "# Start and end dates for download\n",
    "st_dt = \"1900-01-01\"\n",
    "end_dt = \"2024-08-28\"\n",
    "\n",
    "# Station coords \n",
    "station_coords = {\n",
    "    \"15.61.0\": {\"latitude\": 59.18906, \"longitude\": 9.99414}, \n",
    "    \"12.534.0\": {\"latitude\": 59.75292, \"longitude\": 10.00727}, \n",
    "    \"12.285.0\": {\"latitude\": 59.88624, \"longitude\": 9.90977},\n",
    "    \"2.605.0\": {\"latitude\": 59.63733, \"longitude\": 11.15354},\n",
    "}\n",
    "\n",
    "# Metadata\n",
    "global_metadata_config = {\n",
    "    \"naming_authority\": \"no.nve\",\n",
    "    \"project\": \"AquaINFRA\",\n",
    "    \"iso_topic_category\": \"inlandWaters\",\n",
    "    \"featureType\": \"timeSeries\",\n",
    "    \"spatial_representation\": \"point\",\n",
    "    \"creator_type\": \"institution\",\n",
    "    \"creator_institution\": \"Norwegian Water Resources and Energy Directorate (NVE)\",\n",
    "    \"creator_name\": \"Norwegian Water Resources and Energy Directorate (NVE)\",\n",
    "    \"institution\": \"Norwegian Water Resources and Energy Directorate (NVE)\",\n",
    "    \"institution_short_name\": \"NVE\",\n",
    "    \"creator_email\": \"NVE\",\n",
    "    \"creator_email\": \"hydrology@nve.no\",\n",
    "    \"creator_url\": \"https://www.nve.no\",\n",
    "    \"data_owner\": \"Norwegian Water Resources and Energy Directorate (NVE)\",\n",
    "    \"source\": \"NVE HydAPI (https://hydapi.nve.no/)\",\n",
    "    \"processing_level\": \"Raw retrieved from NVE HydAPI\",\n",
    "    \"Conventions\": \"CF-1.7, ACDD-1.3\",\n",
    "    \"publisher_name\": \"Norwegian Water Resources and Energy Directorate (NVE)\",\n",
    "    \"publisher_email\": \"hydrology@nve.no\",\n",
    "    \"publisher_institution\": \"Norwegian Water Resources and Energy Directorate (NVE)\",\n",
    "    \"publisher_url\": \"https://www.nve.no\",\n",
    "    \"license\": \"https://data.norge.no/nlod/en\",\n",
    "    \"license_comment\": (\n",
    "         \"Licensed under the Norwegian License for Open Government Data (NLOD), \"\n",
    "         \"compatible with CC BY 3.0 Norge. Data is provided as-is from NVE HydAPI. \"\n",
    "         \"NVE assumes no responsibility for errors. Cite NVE HydAPI as the source.\"\n",
    "    ),\n",
    "    \"keywords\": \"GCMD:EARTH SCIENCE > HYDROLOGY > STREAMFLOW, GCMDLOC:CONTINENT > EUROPE > NORWAY\",\n",
    "    \"keywords_vocabulary\": \"GCMD:GCMD Science Keywords, GCMDLOC:GCMD Locations\",\n",
    "    \"history\": (\n",
    "        \"Data retrieved using NVE HydAPI (https://hydapi.nve.no/) using 1440-minute resolution. \"\n",
    "        \"No modifications applied beyond reshaping to NetCDF. Correction and quality flags follow NVE's documentation.\"\n",
    "    ),\n",
    "    \"correction_quality_notes\": (\n",
    "        \"See https://hydapi.nve.no/UserDocumentation/ for full details.\\n\\n\"\n",
    "        \"Quality types:\\n\"\n",
    "        \"  0: Unknown\\n\"\n",
    "        \"  1: Uncontrolled\\n\"\n",
    "        \"  2: PrimaryControlled\\n\"\n",
    "        \"  3: SecondaryControlled\\n\\n\"\n",
    "        \"Correction types:\\n\"\n",
    "        \"  0: No changes\\n\"\n",
    "        \"  1: Manual- or ice correction\\n\"\n",
    "        \"  2: Interpolation\\n\"\n",
    "        \"  3: Model/series-based estimate\\n\"\n",
    "        \"  4: Daily mean by arithmetic mean\\n\"\n",
    "        \" 13: Based on nearby/similar station\\n\"\n",
    "        \" 14: Statistically estimated missing value\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Where to save data\n",
    "download_date = \"2024-08-28\"  # (for file naming)\n",
    "out_folder = r'../../data/river/discharge/raw'\n",
    "metadata_folder = r'../../data/river/discharge'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032a87b-42c9-4998-8cca-80449cdc3a1d",
   "metadata": {},
   "source": [
    "## Check whether stations are available in HydAPI & save metadata for stations with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab471058-e481-4406-b737-2e45881bf2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1870 stations available in HydAPI.\n",
      "Desired stations missing from HydAPI: ['2.489.0']\n",
      "New river & station_id dictionary:\n",
      "{'Numedalslågen': {'15.61.0': 'Holmfoss'}, 'Drammenselva': {'12.534.0': 'Mjøndalen bru', '12.285.0': 'Døvikfoss'}, 'Glomma': {'2.605.0': 'Solbergfoss'}}\n"
     ]
    }
   ],
   "source": [
    "# List all stations\n",
    "stn_df = nivapy.da.get_nve_hydapi_stations()\n",
    "print(len(stn_df), \"stations available in HydAPI.\")\n",
    "\n",
    "# Check whether desired stations are available\n",
    "station_id_li = [stn_id for river in stn_id_name_dict.values() for stn_id in river.keys()]\n",
    "missing_station_ids = []\n",
    "\n",
    "for stn_id in station_id_li:\n",
    "    # Check if the station ID is in the DataFrame's 'station_id' column\n",
    "    if stn_id not in stn_df['station_id'].values:\n",
    "        missing_station_ids.append(stn_id)\n",
    "\n",
    "print(f\"Desired stations missing from HydAPI: {missing_station_ids}\")\n",
    "\n",
    "# Drop missing stations from the dictionary of stations we want to download data for\n",
    "for river, stations in stn_id_name_dict.items():\n",
    "    for stn_id in list(stations.keys()):  # Use list() to avoid modifying the dictionary while iterating\n",
    "        if stn_id in missing_station_ids:\n",
    "            del stations[stn_id]\n",
    "\n",
    "# Drop missing stations from station_id_li\n",
    "station_id_li = [stn_id for stn_id in station_id_li if stn_id not in missing_station_ids]\n",
    "\n",
    "print(\"New river & station_id dictionary:\")\n",
    "print(stn_id_name_dict)\n",
    "\n",
    "# Extract metadata for these stations & save to csv\n",
    "select_stn_df = stn_df[stn_df['station_id'].isin(station_id_li)]\n",
    "fpath = os.path.join(metadata_folder, \"discharge_stations_metadata.csv\")\n",
    "select_stn_df.to_csv(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21320716-4017-49dd-ba79-05d3e10c1a84",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "See here for an interpretation of the correction and quality integer values in the data: https://hydapi.nve.no/UserDocumentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b5128c-69a7-4585-887a-40e3d9758237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15788/47284725.py:76: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1970-01-01'. Serializing with units 'hours since 1970-01-01' instead. Set encoding['dtype'] to floating point dtype to serialize with units 'days since 1970-01-01'. Set encoding['units'] to 'hours since 1970-01-01' to silence this warning .\n",
      "  ds.to_netcdf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded & saved data for Holmfoss, 15.61.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15788/47284725.py:76: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1970-01-01'. Serializing with units 'hours since 1970-01-01' instead. Set encoding['dtype'] to floating point dtype to serialize with units 'days since 1970-01-01'. Set encoding['units'] to 'hours since 1970-01-01' to silence this warning .\n",
      "  ds.to_netcdf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded & saved data for Mjøndalen bru, 12.534.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15788/47284725.py:76: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1970-01-01'. Serializing with units 'hours since 1970-01-01' instead. Set encoding['dtype'] to floating point dtype to serialize with units 'days since 1970-01-01'. Set encoding['units'] to 'hours since 1970-01-01' to silence this warning .\n",
      "  ds.to_netcdf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded & saved data for Døvikfoss, 12.285.0\n",
      "Downloaded & saved data for Solbergfoss, 2.605.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15788/47284725.py:76: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1970-01-01'. Serializing with units 'hours since 1970-01-01' instead. Set encoding['dtype'] to floating point dtype to serialize with units 'days since 1970-01-01'. Set encoding['units'] to 'hours since 1970-01-01' to silence this warning .\n",
      "  ds.to_netcdf(\n"
     ]
    }
   ],
   "source": [
    "for river, station_dict in stn_id_name_dict.items():\n",
    "    for station_id, station_name in station_dict.items():\n",
    "        df = nivapy.da.query_nve_hydapi([station_id], par_ids, st_dt, end_dt, resolution=1440)\n",
    "        df.set_index(\"datetime\", inplace=True)\n",
    "        df.index = pd.to_datetime(df.index)  \n",
    "\n",
    "        # File names\n",
    "        fname_csv = f\"Q_daily-mean_{river}_{station_name}_{station_id}_download-{download_date}.csv\"\n",
    "        fname_nc = f\"Q_daily-mean_{river}_{station_name}_{station_id}_download-{download_date}.nc\"\n",
    "        \n",
    "\n",
    "        # Rename and reduce to necessary columns\n",
    "        df_netcdf = df[[\"value\", \"correction\", \"quality\"]].copy()\n",
    "        df_netcdf.rename(columns={\"value\": \"discharge\"}, inplace=True)\n",
    "\n",
    "        # Convert to xarray dataset\n",
    "        ds = df_netcdf.to_xarray()\n",
    "        ds = ds.rename({\"datetime\": \"time\"})\n",
    "        ds[\"time\"] = pd.to_datetime(ds[\"time\"].values).astype(\"datetime64[ns]\") \n",
    "        \n",
    "        ds[\"time\"].attrs.update({\n",
    "            \"standard_name\": \"time\",\n",
    "            \"long_name\": \"Date of observation\",\n",
    "            \"axis\": \"T\"\n",
    "        })\n",
    "\n",
    "        # Get coordinates\n",
    "        coords = station_coords.get(station_id, {\"latitude\": np.nan, \"longitude\": np.nan})\n",
    "        lat = float(coords[\"latitude\"])\n",
    "        lon = float(coords[\"longitude\"])\n",
    "\n",
    "        # Add scalar coordinate variables\n",
    "        ds = ds.assign_coords(\n",
    "            latitude=xr.DataArray(lat, dims=(), attrs={\n",
    "                \"standard_name\": \"latitude\", \"long_name\": \"Latitude\", \"units\": \"degrees_north\"\n",
    "            }),\n",
    "            longitude=xr.DataArray(lon, dims=(), attrs={\n",
    "                \"standard_name\": \"longitude\", \"long_name\": \"Longitude\", \"units\": \"degrees_east\"\n",
    "            }),\n",
    "        )\n",
    "        ds = ds.set_coords([\"latitude\", \"longitude\"])\n",
    "\n",
    "        # Add scalar station info\n",
    "        ds[\"station_id\"] = xr.DataArray(station_id, dims=())\n",
    "        ds[\"station_name\"] = xr.DataArray(station_name, dims=(), attrs={\"cf_role\": \"timeseries_id\"})\n",
    "\n",
    "        # Add attributes to discharge\n",
    "        ds[\"discharge\"].attrs.update({\n",
    "            \"units\": df[\"unit\"].iloc[0],\n",
    "            \"long_name\": \"Daily mean river discharge\",\n",
    "            \"standard_name\": \"discharge\"\n",
    "        })\n",
    "\n",
    "        # Global metadata\n",
    "        dataset_metadata = global_metadata_config.copy()\n",
    "        dataset_metadata.update({\n",
    "            \"title\": f\"Discharge at {station_name}\",\n",
    "            \"summary\": f\"Daily mean discharge time series from NVE HydAPI at station {station_name} ({station_id}) on river {river}.\",\n",
    "            \"method\": str(df[\"method\"].iloc[0]),\n",
    "            \"parameter_id\": int(df[\"parameter\"].iloc[0]),\n",
    "            \"parameter_name_no\": str(df[\"parameter_name\"].iloc[0]),\n",
    "            \"parameter_name_eng\": str(df[\"parameter_name_eng\"].iloc[0]),\n",
    "            \"geospatial_lat_min\": lat,\n",
    "            \"geospatial_lat_max\": lat,\n",
    "            \"geospatial_lon_min\": lon,\n",
    "            \"geospatial_lon_max\": lon,\n",
    "            \"time_coverage_start\": str(df.index.min().date()),\n",
    "            \"time_coverage_end\": str(df.index.max().date()),\n",
    "            \"download_date\": download_date,\n",
    "        })\n",
    "        \n",
    "        ds.attrs.update(dataset_metadata)\n",
    "\n",
    "        # Save files\n",
    "        df.to_csv(os.path.join(out_folder, fname_csv))\n",
    "        ds.to_netcdf(\n",
    "            os.path.join(out_folder, fname_nc),\n",
    "            encoding={\n",
    "                \"time\": {\n",
    "                    \"dtype\": \"int32\",\n",
    "                    \"units\": \"days since 1970-01-01\",\n",
    "                    \"calendar\": \"standard\"\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"Downloaded & saved data for {station_name}, {station_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5946a7-83aa-4b69-8fc1-06d6004564ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
